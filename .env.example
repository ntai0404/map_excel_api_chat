# --- AI Configuration ---
# API Key (Google Gemini or Custom)
AI_API_KEY=YOUR_API_KEY_HERE

# Model Name (e.g., gemini-2.0-flash, gemini-1.5-flash, llama3, qwen:7b)
AI_MODEL_NAME=gemini-2.0-flash

# API Base URL (Optional)
# Leave empty for standard Google Gemini.
# Set to 'http://localhost:11434' for Ollama (Local) or custom proxy IP.
# AI_API_BASE=http://localhost:11434

# --- Legacy Support ---
GEMINI_API_KEY=YOUR_API_KEY_HERE
